\documentclass[11pt]{article}

\usepackage{fullpage}
\usepackage{newtxtext}
\usepackage{microtype}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage[amsmath,amsthm,thmmarks,hyperref]{ntheorem}
\usepackage[pagebackref=true]{hyperref} % must set backref at load time
\usepackage{fancyhdr}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage[svgnames]{xcolor}
\usepackage{tikz}
\usepackage{import}

% load after hyperref, algpseudocode to get proper behavior
\usepackage[capitalize,nameinlink,noabbrev]{cleveref}

\import{common/}{head.tex}

% VARIABLES

\newcommand{\lecturenum}{4}
\newcommand{\lecturetopic}{Coppersmith, Cryptanalysis}
\newcommand{\scribename}{Jacob Alperin-Sheriff}

\DeclareMathOperator{\res}{res}

% END OF VARIABLES

\import{common/}{lechead.tex}
\lecheader                      % execute lecture commands

\pagestyle{plain}               % default: no special header

\begin{document}

\thispagestyle{fancy} % first page should have special header

% LECTURE MATERIAL STARTS HERE

\section{Coppersmith's Theorem}
\label{sec:coppersmith}

Today we prove the ``full version'' of Coppersmith's
Theorem~\cite{DBLP:conf/eurocrypt/Coppersmith96}, stated here.

\begin{theorem}
  \label{thm:coppersmith}
  Let $N$ be a positive integer and $f(x) \in \Z[x]$ be a monic
  degree-$d$ polynomial. There is an algorithm that, given $N$ and
  $f$, finds all integers $x_{0}$ such that $f(x_{0}) = 0 \bmod N$ and
  $\abs{x_{0}} \leq B \approx N^{1/d}$, in time polynomial in the bit
  length of the inputs.
\end{theorem}

In the theorem statement and what follows, for simplicity we use
$\approx$ to hide factors which are polynomial in $d$ and
$N^{\epsilon}$ for some constant $\epsilon > 0$ that can be made
arbitrarily small.\footnote{This yields a true bound of
  $B = N^{1/d-\epsilon}$, though with more work the theorem can be
  proved for $B=N^{1/d}$.} The remainder of this section is dedicated
to the proof of the theorem.

Last time we considered adding multiples of $N \cdot x^{i}$ to~$f(x)$,
which preserves the roots of $f(x)$ modulo~$N$. But this only let us
obtain a bound of $B \approx N^{2/d^{2}}$. To do better, we consider
higher powers of~$f(x)$ and~$N$. More specifically, our strategy is to
use LLL to efficiently find a nonzero polynomial
$h(x) = \sum_{i} h_{i} x^{i} \in \Z[x]$ of degree at most
$n = d(m+1)$, for some positive integer~$m$ to be determined, such
that:
\begin{enumerate}[itemsep=0pt]
\item Any root of~$f$ modulo~$N$ is a root of~$h$ modulo~$N^{m}$,
  i.e., if $f(x_{0}) = 0 \bmod N$ then $h(x_{0}) = 0 \bmod N^{m}$.
\item The polynomial $h(Bx)$ is ``short,'' i.e., its coefficients
  $h_{i} B^{i}$ are all less than $N^{m}/(n+1)$ in magnitude.
\end{enumerate}
From the second property, it follows that if $\abs{x_{0}} \leq B$,
then
\[ \abs{h(x_{0})} \leq \sum_{i=0}^{n} \abs{h_{i} B^{i}} < N^{m}. \]
Therefore, by the first property, any small root of~$f$ modulo~$N$ is
a root of~$h(x)$ \emph{over the integers} (not modulo anything). So,
having found~$h(x)$, we can efficiently factor it over the integers
and check whether each of its small roots is indeed a root of~$f(x)$
modulo~$N$.

The first helpful insight is that $f(x_{0}) = 0 \bmod N$ implies
$f(x_{0})^{k} = 0 \bmod N^{k}$ for any positive integer~$k$. So, we
can define $n=d(m+1)$ polynomials $g_{u,v}(x)$ whose roots
modulo~$N^{m}$ will include all the roots of $f(x)$ modulo~$N$, as
follows:
\[ g_{u,v}(x)=N^{m-v} \cdot x^{u} \cdot f(x)^{v} \quad \text{for } u
  \in \set{0,\ldots,d-1}, v \in \set{0,\ldots,m}. \] We use two
important facts about these polynomials:
\begin{itemize}
\item First, $g_{u,v}(x)$ has leading coefficient $N^{m-v}$ and is of
  degree exactly $u+vd$, because $f(x)$ is monic and of degree $d$.
\item Second, if~$x_{0}$ is a root of $f(x)$
  modulo~$N$, then~$x_{0}$ is a root of $g_{u,v}(x)$ modulo $N^{m}$ for
  all $u,v$, because~$N^{m}$ divides $N^{m-v} f(x_{0})^{v}$.
\end{itemize}
 
The basis vectors for our lattice are coefficient vectors of
$g_{u,v}(Bx)$ where, to recall, $B$ is the bound on the magnitude of
the roots we seek. In other words, the basis is
$\matB=[\vecb_0,\ldots,\vecb_{n-1}]$, where~$\vecb_{u+vd}$ is the
coefficient vector of $g_{u,v}(Bx)$ as a polynomial in~$x$. Since
$g_{u,v}(x)$ is of degree $u+vd$ with leading coefficient $N^{m-v}$,
and $u+vd$ runs over $\set{0, \ldots, n-1}$ as $u,v$ run over their
respective ranges, the basis is triangular, with diagonal entries
$N^{m-v} B^{u+vd}$. A straightforward calculation then reveals that
\begin{equation}
  \label{eq:det-B}
  \det(\matB) = B^{n(n-1)/2} \cdot N^{d m (m+1)/2}.
\end{equation}

Running the LLL algorithm on $\matB$ yields a nonzero vector
$\vecv \in \lat(\matB)$ of length
\begin{align}
  \length{\vecv} \leq 2^{(n-1)/2} \det(\matB)^{1/n}
  &= 2^{(n-1)/2} \parens*{B^{n(n-1)/2} \cdot N^{d m(m+1)/2}}^{1/n} \\
  &\leq (2 B)^{n/2} \cdot N^{m/2}.
\end{align}
Setting $B \approx (N^{1/d})^{m/(m+1)}$, which is $N^{1/d-\epsilon}$
for large enough (but still polynomially bounded) $m$, we can ensure
that $(2B)^{n/2} < N^{m/2}/(n+1)$ and therefore that
$\length{\vecv} < N^{m}/(n+1)$, as required. Reading off the entries
of $\vecv$ as the coefficients of $h(Bx)$ yields a satisfactory
polynomial $h(x)$.

\section{Cryptanalysis of RSA Variants}
\label{sec:crypt-rsa}

One of the most interesting applications of Coppersmith's algorithm is
to attack variants of RSA.

\subsection{RSA Recap}
\label{sec:rsa-recap}

The RSA function and cryptosystem~\cite{DBLP:journals/cacm/RivestSA78}
(named after its inventors Rivest, Shamir and Adleman) is one of the
most widely used public-key encryption and digital signature schemes
in practice.

It is important to distinguish between the RSA \emph{function} and an
RSA-based cryptosystem. The RSA function is defined as follows. Let
$N=pq$, where $p$ and $q$ are distinct very large primes (according to
current security recommendations, they should be at least $1{,}000$
bits each). Let $e$ be a public ``encryption exponent'' such that
$\gcd(e,\varphi(N))=1$, where
$\varphi(N) = \abs{\Z_{N}^{*}} = (p-1)(q-1)$ is the totient function.
The RSA function $f_{e,N} \colon \Z_{N}^{*} \to \Z_{N}^{*}$ is defined
by the public values $(N,e)$ as follows:
\begin{equation}
  \label{eq:rsa}
  f_{e,N}(x) := x^{e} \bmod N.
\end{equation}
It is conjectured that, given just $N,e$, and $y=f_{e,N}(x)$ for a
uniformly random $x \in \Z_{N}^{*}$, it is computationally infeasible
to find $x$. However, one can efficiently invert the RSA function
using some extra ``trapdoor'' information: let~$d$ be the ``decryption
exponent'' defined by $e \cdot d=1 \bmod \varphi(N)$, which is
efficiently computable given the factorization of~$N$. Then the
inverse of the RSA function is
\begin{equation}
  \label{eq:rsa-inv}
  f_{e,N}^{-1}(y) := y^{d} \bmod N.
\end{equation}
This indeed inverts the function because, for
$y=f_{e,N}(x) = x^{e} \bmod N$, we have
\[ y^d=(x^e)^d = (x^{e \cdot d \bmod \varphi(N)}) = x \bmod N, \]
where the first inequality holds because the order of the
group~$\Z_{N}^{*}$ is~$\varphi(N)$, and by Euler's Theorem. It follows
that~$f_{e,N}$ is a bijection (also called a \emph{permutation})
on~$\Z_{N}^{*}$.

\subsection{Low-Exponent Attacks}
\label{sec:low-exponent-attacks}

Because exponentiation modulo huge integers is somewhat
computationally expensive, many early proposals advocated using
encryption exponents as small as $e=3$ with RSA, due to some
significant efficiency benefits.\footnote{Note that one cannot use
  $e=2$ (or any other even $e$) because it is never coprime with
  $\varphi(N)$, which is also even.} For example, using an encryption
exponent of the form $e=2^{k}+1$, one can compute $x^{e}$ using only
$k+1$ modular multiplications via the standard ``repeated squaring''
method.  Moreover, the basic RSA function still appears to be hard to
invert (on uniformly random $y \in \Z_{N}^{*}$) for small~$e$.

Like any other deterministic public-key encryption scheme, the RSA
function itself is not a secure cryptosystem. This is because if an
attacker had a guess about the message in a ciphertext $c$ (say,
because the number of possible messages was small), it could easily
test whether its guess was correct by encrypting the message and
checking whether the resulting ciphertext matched $c$. Therefore, one
needs to use a \emph{randomized} encryption algorithm. The most
obvious way to randomize the RSA function is to append some random
``padding'' bits to the end of the message before encrypting. However,
devising a secure padding scheme is quite difficult and subtle, due to
the existence of clever attacks using tools like LLL. Here we describe
one such attack: when~$e$ is small and the padding is not long enough,
the attack efficiently recovers an encrypted message~$M$ given just
two encryptions of~$M$ with different paddings.\footnote{In real-life
  applications it is quite common to encrypt the same message more
  than once, e.g., via common protocol headers or retransmission.}

We start with a simple ``related-message attack''
of~\cite{DBLP:conf/eurocrypt/CoppersmithFPR96}, which is interesting
in its own right and will also be a key component of the padding
attack. Note that this attack is on the deterministic RSA function.

\begin{lemma}
  \label{lem:related-msg}
  Let $e=3$ and $M_1, M_2 \in \Z_{N}^*$ satisfy
  $M_1=\ell(M_2) \bmod N$, where $\ell(M)=aM+b$ for some $a,b\neq 0$
  is a known linear function. Then one can efficiently recover
  $M_1, M_2$ from $C_1=M_1^{e} \bmod N$ and $C_2=M_2^e \bmod N$ (and
  the other public information $N,e,a,b$).\footnote{It turns out that
    theorem is ``usually'' true even for $e>3$, but there are rare
    exceptions.}
\end{lemma}

\begin{proof}
  Define polynomials
  $g_1(x)=\ell(x)^{e}-C_1, g_2(x)=x^{e}-C_2 \in \Z_{N}[x]$. Notice
  that~$M_2$ is a root of both~$g_1$ and~$g_2$, and thus $(x-M_2)$ is
  a common divisor of~$g_1$ and~$g_2$ (here is where we need that
  $a \neq 0$). If it is in fact the greatest common divisor (i.e., the
  common divisor of largest degree), then we can find it using
  Euclid's algorithm.\footnote{Strictly speaking, Euclid's algorithm
    would normally require $\Z_{N}$ to be a field, which it is not.
    However, if Euclid's algorithm fails in this setting then it
    reveals the factorization of~$N$ as a side effect, which lets us
    compute the decryption exponent and the messages.} We show next
  that $(x-M_{2})$ is indeed the greatest common divisor.

  First observe that for any $C \in \Z_{N}^*$, the polynomial $x^3-C$
  has only one root modulo $N$, because the RSA function is a
  bijection. As a result, we have
  $g_2(x)=x^3-C_2=(x-M_{2})(x^2+\beta_1x+\beta_0)$, where the
  quadratic term is irreducible, so $\gcd(g_{1}, g_{2})$ is either
  $(x-M_{2})$ or $g_{2}$.  Since $b \neq 0$, we have that $g_2(x)
  \nmid g_1(x)$, and therefore the greatest common divisor is indeed
  $x-M_{2}$.
\end{proof}

We now consider a potential padding method: to encrypt a message $M$,
one appends $m$ uniformly random bits $r \in \bit^{m}$ (for some
publicly known value of $m$), and applies the RSA function:
\[ C=f_{N,e}(M \| r). \] (Upon decryption, the padding bits are
ignored.) Mathematically, this corresponds to transforming~$M$ to
$2^{m} \cdot M + r$ for uniformly random
$r \in \set{0, \ldots, 2^{m}-1}$. Note that $M$ must be short enough,
and $m$ small enough, so that the result can be interpreted as an
element of $\Z_{N}^{*}$ and unambiguously represents~$M$.

The following theorem of~\cite{DBLP:journals/joc/Coppersmith97} shows
that if the pad length is too short (as determined by the size
of~$e$), then it is possible to efficiently recover the message~$M$
from two distinct encryptions of it. Notice that for $e=3$, a pad
length of $n/9 \approx 2{,}000/9 \approx 222$ is large enough to
prevent any repeated pad values with overwhelming probability, yet it
still provides essentially no security.

\begin{theorem}
  \label{thm:small-e-padding}
  Let $N$ have bit length $n$, let $e=3$, and let
  $m \leq \floor{n/e^2}$ be the padding length (in bits). Given two
  encryptions $C_1, C_2$ of the same message~$M$ with arbitrary
  distinct pads $r_{1}, r_{2} \in \set{0, \ldots, 2^{m}-1}$, one can
  efficiently recover~$M$.
\end{theorem}

\begin{proof}
  We have $M_1 = 2^{m}\cdot M+r_1$ and $M_2=2^{m}\cdot M+r_2$ for some
  distinct $r_1,r_2 \in \{0,\ldots, 2^{m}-1\}$.  We define two
  bivariate polynomials $g_{1}(x,y), g_{2}(x,y) \in \Z_{N}[x]$ as
  \begin{align}
    g_1(x,y) &= x^{e} - C_1 = x^{e}-M_1^{e}, \\
    g_2(x,y) &= (x+y)^{e}-C_2=(x+y)^{e}-M_2^{e} .
  \end{align}
  Essentially, $x$ represents the unknown message, and $y$ represents
  the unknown pads. Since $g_1$ is independent of $y$, we have that
  $(x=M_1, y = \star)$ is a root of $g_1$ for any value of $y$.
  Similarly, $(x=M_{1}, y=r_2-r_1)$ is a root of $g_2$.

  To take the next step, we need a concept called the \emph{resultant}
  of two polynomials in a variable $x$, which is defined as the
  product of all the differences between their respective roots:
  \[ \res_x(p(x),q(x))=\prod_{p(x_0)=q(x_1)=0}(x_0-x_1). \] In our
  setting, we treat the bivariate polynomials $g_{i}(x,y)$ as
  polynomials in $x$ whose coefficients are polynomials in $y$ (i.e.,
  elements of $\Z_{N}[y]$), so $\res_{x}(g_{1}, g_{2})$ is a
  polynomial in~$y$.

  We use a few important facts about the resultant:
  \begin{itemize}[itemsep=0pt]
  \item First, it is clear that $\res_x(p(x),q(x))=0$ when $p,q$ have
    a common root.
  \item Second, $\res_x(p,q)=\det(\matS_{p,q})$, where $\matS_{p,q}$
    is a square $(\deg{p}+\deg{q})$-dimensional matrix called the
    Sylvester matrix, whose entries are made up of various shifts of
    the coefficient vectors of $p$ and $q$. Therefore, the resultant
    can be computed efficiently.
  \item Finally, in our setting the $x$-coefficients of~$g_{1}$ are
    constant (i.e., degree-$0$) polynomials in~$y$, while the
    $x$-coefficients of~$g_{2}$ are polynomials of degree at most~$e$
    in~$y$. By definition of the Sylvester matrix, the resultant
    $h(y) = \res_{x}(g_{1}, g_{2})$ has degree at most~$e^{2}$ in~$y$.
  \end{itemize}

  We claim that $\Delta=r_2-r_1 \neq 0$, which has absolute value
  $\abs{\Delta} \leq 2^{m} < N^{1/e^{2}}$, is a root of the resultant
  $h(y)=\res_x(g_1,g_2)$. This is because the univariate polynomials
  $g_1(x,\Delta)$ and $g_2(x,\Delta)$ have a common root $x=M_{1}$.

  Armed with this information, our attack proceeds as follows. We
  construct the polynomials $g_1, g_2$, and compute the resultant
  $h(y)=\res_x(g_1,g_2)$. Then $\deg(h(y)) \leq e^2$, and we know that
  $h(y)$ has $\Delta=r_2-r_1 \neq 0$ as a root modulo~$N$. We run
  Coppersmith's algorithm on $h(y)$, and since
  $\abs{\Delta} \leq 2^{m} < N^{1/e^2}$, we get a polynomial-length
  list of small roots that contains~$\Delta$. Trying each element of
  the list as a candidate for~$\Delta$, we have a known (candidate)
  linear function $\ell(M) = M - \Delta$ where
  $M_{1} = \ell(M_{2})$, and we can run the related message attack
  from \cref{lem:related-msg}.\footnote{Note that we have rigorously
    proved \cref{lem:related-msg} only for the case $e=3$, but the
    attack works as long as the associated algorithm actually
    succeeds.} One of these runs involves the correct value
  of~$\Delta$ and thus reveals $M_{1}, M_{2}$, and we can confirm
  which run does so by re-encrypting and checking against
  $C_{1}, C_{2}$.
\end{proof}

The above is just one of countless lattice attacks against classical
number-theoretic cryptography, not limited to variants of RSA:
\begin{itemize}[itemsep=0pt]
\item Small decryption exponent~$d$: for more efficient decryption, a
  natural idea is to use a relatively small decryption exponent~$d$
  (with whatever~$e$ it induces). However, this can be completely
  insecure: to date, the best known attack efficiently recovers~$d$ if
  it is less than $N^{0.292}$~\cite{DBLP:journals/tit/BonehD00}. This
  uses a bivariate version of
  Coppersmith~\cite{DBLP:conf/eurocrypt/Coppersmith96a} that lacks a
  rigorous proof of correctness in general, but seems to work well
  empirically. Important open questions are whether
  $d < N^{1/2-\epsilon}$ is efficiently attackable (it is conjectured
  to be, but no effective attack has been found in the more than 25
  years since the conjecture was made), and whether there are
  rigorously provable variants of Coppersmith for bivariate or
  multivariate polynomials.

\item Partial secret key exposure: when certain bits of~$d$ or the
  factors $p,q$ of~$N$ are known to the attacker, it is often possible
  to efficiently recover them completely. See,
  e.g.,~\cite{DBLP:conf/eurocrypt/Coppersmith96a,DBLP:conf/asiacrypt/BonehDF98}.

\item Larger powers of prime factors: for integers of the form
  $N=p^{r} q$ for larger $r > 1$, there is a specialized lattice-based
  attack~\cite{DBLP:conf/crypto/BonehDH99}. The performance improves
  as~$r$ increases, resulting in a polynomial-time attack when~$r$ is
  on the order of~$\log p$.

\item Partially known or biased `nonces': many signature schemes that
  rely on the hardness of discrete logarithms, such as the (Elliptic
  Curve) Digital Signature Algorithm, or (EC)DSA, generate a secret
  random `nonce' value during signing. If partial information about
  the nonce is leaked, or if nonces are non-uniformly biased, then
  there are effective lattice attacks that recover the secret signing
  key. See,
  e.g.,~\cite{DBLP:journals/dcc/Howgrave-GrahamS01,DBLP:journals/joc/NguyenS02,DBLP:journals/dcc/NguyenS03}.
\end{itemize}

\bibliography{common/lattices,common/crypto}
\bibliographystyle{common/alphaabbrvprelim}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
